{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMA - Porc & Pines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGzICPJbDGnI77LHN8OxtE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GonzoDen/NMA-CN/blob/main/NMA_Porc_%26_Pines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8msxXayvihf"
      },
      "source": [
        "**Research Question:** What cortical regions are responsible for math and story problem solving? How do cortical regions interact to produce math and story problem processing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMdUvtOmwqNB"
      },
      "source": [
        "Simplest model:\n",
        "1. Maybe we can start by testing whether our program can extract the data\n",
        "  - Copy necessary data from the initial data notebook\n",
        "  - Extract most active 20+20 parcels\n",
        "  - Build a matrix for ONE subject and 20 language parcels\n",
        "      - No mean, I guess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXsfboBSvhyn"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4VIL-lEyYU8"
      },
      "source": [
        "Basic Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC6mDT_1bn9S"
      },
      "source": [
        "# The download cells will store the data in nested directories starting here:\n",
        "HCP_DIR = \"./hcp\"\n",
        "if not os.path.isdir(HCP_DIR):\n",
        "  os.mkdir(HCP_DIR)\n",
        "\n",
        "# The data shared for NMA projects is a subset of the full HCP dataset\n",
        "N_SUBJECTS = 339 ##initial 339\n",
        "\n",
        "# The data have already been aggregated into ROIs from the Glasesr parcellation\n",
        "N_PARCELS = 360 ##\n",
        "\n",
        "# The acquisition parameters for all tasks were identical\n",
        "TR = 0.72  # Time resolution, in sec\n",
        "\n",
        "# The parcels are matched across hemispheres with the same order\n",
        "HEMIS = [\"Right\", \"Left\"]\n",
        "\n",
        "# Each experiment was repeated multiple times in each subject\n",
        "##N_RUNS_REST = 4\n",
        "N_RUNS_TASK = 2\n",
        "\n",
        "# Time series data are organized by experiment, with each experiment\n",
        "# having an LR and RL (phase-encode direction) acquistion\n",
        "## initial BOLD_NAMES are bigger removed for the sake of project\n",
        "BOLD_NAMES = [\n",
        "  \"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\", ##TODO: how to find resting state code\n",
        "  \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\",\n",
        "  \"tfMRI_MOTOR_RL\", \"tfMRI_MOTOR_LR\",\n",
        "  \"tfMRI_WM_RL\", \"tfMRI_WM_LR\",\n",
        "  \"tfMRI_EMOTION_RL\", \"tfMRI_EMOTION_LR\",\n",
        "  \"tfMRI_GAMBLING_RL\", \"tfMRI_GAMBLING_LR\",\n",
        "  \"tfMRI_LANGUAGE_RL\", \"tfMRI_LANGUAGE_LR\", ##TA: which direction we need to choose\n",
        "  \"tfMRI_RELATIONAL_RL\", \"tfMRI_RELATIONAL_LR\",\n",
        "  \"tfMRI_SOCIAL_RL\", \"tfMRI_SOCIAL_LR\"\n",
        "]\n",
        "\n",
        "# You may want to limit the subjects used during code development.\n",
        "# This will use all subjects:\n",
        "subjects = range(N_SUBJECTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryBvuO7vcMrq"
      },
      "source": [
        "**DOWNLOADING DATA **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFNa2qQYtM83"
      },
      "source": [
        "#!rm -rf hcp\n",
        "#maybe then creating a bash command to delete anything that is not related to the language task?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5VsDDPwg_Nr"
      },
      "source": [
        "TODO: probably will have to delete folders later or whatever "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczV8t41cMJI"
      },
      "source": [
        "fname = \"hcp_task.tgz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/s4h8j/download/\n",
        "  !tar -xzf $fname -C $HCP_DIR --strip-components=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLED8zcMcW6u"
      },
      "source": [
        "Only language part (still loading btw):\n",
        "- will it distribute subjects in different folders?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzdco7UopTEC"
      },
      "source": [
        "Loading data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teObe5LIpSuJ"
      },
      "source": [
        "def get_image_ids(name):\n",
        "  \"\"\"Get the 1-based image indices for runs in a given experiment.\n",
        "\n",
        "    Args:\n",
        "      name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    Returns:\n",
        "      run_ids (list of int) : Numeric ID for experiment image files\n",
        "\n",
        "  \"\"\"\n",
        "  run_ids = [\n",
        "    i for i, code in enumerate(BOLD_NAMES, 1) if name.upper() in code\n",
        "  ]\n",
        "  if not run_ids:\n",
        "    raise ValueError(f\"Found no data for '{name}''\")\n",
        "  return run_ids\n",
        "\n",
        "def load_timeseries(subject, name, runs=None, concat=True, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject.\n",
        "  \n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    run (None or int or list of ints): 0-based run(s) of the task to load,\n",
        "      or None to load all runs.\n",
        "    concat (bool) : If True, concatenate multiple runs in time\n",
        "    remove_mean (bool) : If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_tp array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  # Get the list relative 0-based index of runs to use\n",
        "  if runs is None:\n",
        "    runs = range(N_RUNS_REST) if name == \"rest\" else range(N_RUNS_TASK)\n",
        "  elif isinstance(runs, int):\n",
        "    runs = [runs]\n",
        "\n",
        "  # Get the first (1-based) run id for this experiment \n",
        "  offset = get_image_ids(name)[0]\n",
        "\n",
        "  # Load each run's data\n",
        "  bold_data = [\n",
        "      load_single_timeseries(subject, offset + run, remove_mean) for run in runs\n",
        "  ]\n",
        "\n",
        "  # Optionally concatenate in time\n",
        "  if concat:\n",
        "    bold_data = np.concatenate(bold_data, axis=-1)\n",
        "\n",
        "  return bold_data\n",
        "\n",
        "\n",
        "def load_single_timeseries(subject, bold_run, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject and single run.\n",
        "  \n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    bold_run (int): 1-based run index, across all tasks\n",
        "    remove_mean (bool): If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  bold_path = f\"{HCP_DIR}/subjects/{subject}/timeseries\"\n",
        "  bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
        "  ts = np.load(f\"{bold_path}/{bold_file}\")\n",
        "  if remove_mean:\n",
        "    ts -= ts.mean(axis=1, keepdims=True)\n",
        "  return ts\n",
        "\n",
        "def load_evs(subject, name, condition):\n",
        "  \"\"\"Load EV (explanatory variable) data for one task condition.\n",
        "\n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of task\n",
        "    condition (str) : Name of condition\n",
        "\n",
        "  Returns\n",
        "    evs (list of dicts): A dictionary with the onset, duration, and amplitude\n",
        "      of the condition for each run.\n",
        "\n",
        "  \"\"\"\n",
        "  evs = []\n",
        "  for id in get_image_ids(name):\n",
        "    task_key = BOLD_NAMES[id - 1]\n",
        "    ev_file = f\"{HCP_DIR}/subjects/{subject}/EVs/{task_key}/{condition}.txt\"\n",
        "    ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
        "    ev = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
        "    evs.append(ev)\n",
        "  return evs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6MQ4ZYYvFWz"
      },
      "source": [
        "Task-based Analysis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvUo_8kPvIQg"
      },
      "source": [
        "def condition_frames(run_evs, skip=0):\n",
        "  \"\"\"Identify timepoints corresponding to a given condition in each run.\n",
        "\n",
        "  Args:\n",
        "    run_evs (list of dicts) : Onset and duration of the event, per run\n",
        "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
        "      for hemodynamic lag\n",
        "\n",
        "  Returns:\n",
        "    frames_list (list of 1D arrays): Flat arrays of frame indices, per run\n",
        "\n",
        "  \"\"\"\n",
        "  frames_list = []\n",
        "  for ev in run_evs:\n",
        "\n",
        "    # Determine when trial starts, rounded down\n",
        "    start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
        "\n",
        "    # Use trial duration to determine how many frames to include for trial\n",
        "    duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
        "\n",
        "    # Take the range of frames that correspond to this specific trial\n",
        "    frames = [s + np.arange(skip, d) for s, d in zip(start, duration)]\n",
        "\n",
        "    frames_list.append(np.concatenate(frames))\n",
        "\n",
        "  return frames_list\n",
        "\n",
        "\n",
        "def selective_average(timeseries_data, ev, skip=0):\n",
        "  \"\"\"Take the temporal mean across frames for a given condition.\n",
        "\n",
        "  Args:\n",
        "    timeseries_data (array or list of arrays): n_parcel x n_tp arrays\n",
        "    ev (dict or list of dicts): Condition timing information\n",
        "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
        "      for hemodynamic lag\n",
        "\n",
        "  Returns:\n",
        "    avg_data (1D array): Data averagted across selected image frames based\n",
        "    on condition timing\n",
        "\n",
        "  \"\"\"\n",
        "  # Ensure that we have lists of the same length\n",
        "  if not isinstance(timeseries_data, list):\n",
        "    timeseries_data = [timeseries_data]\n",
        "  if not isinstance(ev, list):\n",
        "    ev = [ev]\n",
        "  if len(timeseries_data) != len(ev):\n",
        "    raise ValueError(\"Length of `timeseries_data` and `ev` must match.\")\n",
        "\n",
        "  # Identify the indices of relevant frames\n",
        "  frames = condition_frames(ev, skip)\n",
        "\n",
        "  # Select the frames from each image\n",
        "  selected_data = []\n",
        "  for run_data, run_frames in zip(timeseries_data, frames):\n",
        "    run_frames = run_frames[run_frames < run_data.shape[1]]\n",
        "    selected_data.append(run_data[:, run_frames])\n",
        "\n",
        "  # Take the average in each parcel\n",
        "  avg_data = np.concatenate(selected_data, axis=-1).mean(axis=-1)\n",
        "\n",
        "  return avg_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WbCfmBnvU08"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwAQWPLjvVKx"
      },
      "source": [
        "timeseries_task = []\n",
        "for subject in subjects:\n",
        "  timeseries_task.append(load_timeseries(subject, \"language\", concat=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ro0C2pzvgx"
      },
      "source": [
        "Dividing into subsets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV5WqTbDzvOF"
      },
      "source": [
        "train_set = []\n",
        "test_set = []\n",
        "\n",
        "for subject in subjects:\n",
        "    if np.random.choice(2, p=[0.6, 0.4])==0:\n",
        "        train_set.append(subject) \n",
        "        \n",
        "    else:\n",
        "        test_set.append(subject)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZA5GCoN3e9S",
        "outputId": "f2e3cce6-a7e9-46d4-ca58-24c908c0e2a2"
      },
      "source": [
        "print(train_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 2, 3, 5, 6, 11, 12, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 41, 44, 45, 46, 49, 50, 52, 55, 57, 59, 61, 64, 65, 66, 67, 68, 70, 71, 72, 73, 77, 78, 79, 80, 81, 83, 85, 87, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 102, 103, 104, 109, 110, 111, 112, 113, 114, 119, 120, 124, 126, 128, 129, 132, 133, 134, 135, 136, 137, 138, 143, 145, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 163, 164, 165, 167, 168, 172, 173, 177, 178, 179, 181, 182, 183, 184, 185, 186, 188, 189, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 207, 210, 211, 212, 215, 217, 218, 220, 221, 222, 224, 225, 226, 227, 229, 230, 233, 234, 235, 238, 239, 241, 242, 243, 244, 245, 249, 250, 253, 255, 256, 257, 258, 259, 263, 265, 267, 269, 270, 272, 273, 274, 276, 278, 280, 281, 282, 283, 288, 289, 291, 295, 299, 300, 304, 305, 306, 307, 309, 311, 313, 318, 319, 321, 322, 323, 324, 325, 326, 327, 329, 332, 334, 335, 338]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLs0EoJ9gOCB"
      },
      "source": [
        "Substraction Analysis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtiHnC4ugRHD"
      },
      "source": [
        "task = \"language\"\n",
        "\n",
        "N_MAX_PARCELS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9bShahM5XtN"
      },
      "source": [
        "#story\n",
        "conditions_story = [\"response_story\",\"cue\"]   # Run a substraction analysis between two conditions\n",
        "\n",
        "contrast_story = []\n",
        "\n",
        "for subject in subjects:\n",
        "\n",
        "  # Get the average signal in each region for each condition\n",
        "  evs = [load_evs(subject, task, cond) for cond in conditions_story] ##??? how can we get conditions\n",
        "  avgs = [selective_average(timeseries_task[subject], ev) for ev in evs]\n",
        "\n",
        "  # Store the region-wise difference\n",
        "  contrast_story.append(avgs[0] - avgs[1])\n",
        "\n",
        "group_contrast_story = np.mean(contrast_story, axis=0) #a contrast btw cond1 and 2 of the \"average\" subject "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgO1_kGx6pJx"
      },
      "source": [
        "max_ind_story = group_contrast_story.argsort()[-N_MAX_PARCELS:][::-1] #found intexes of the most active parcels for story activity\n",
        "#thresh = min(group_contrast_story[max_ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfspJXuH5dor"
      },
      "source": [
        "#math\n",
        "conditions_math = [\"response_math\",\"cue\"]   # Run a substraction analysis between two conditions\n",
        "\n",
        "contrast_math = []\n",
        "\n",
        "for subject in subjects:\n",
        "\n",
        "  # Get the average signal in each region for each condition\n",
        "  evs = [load_evs(subject, task, cond) for cond in conditions_math] ##??? how can we get conditions\n",
        "  avgs = [selective_average(timeseries_task[subject], ev) for ev in evs]\n",
        "\n",
        "  # Store the region-wise difference\n",
        "  contrast_math.append(avgs[0] - avgs[1])\n",
        "\n",
        "group_contrast_math = np.mean(contrast_math, axis=0) #a contrast btw cond1 and 2 of the \"average\" subject "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6biYVVgbsK"
      },
      "source": [
        "max_ind_math = group_contrast_math.argsort()[-N_MAX_PARCELS:][::-1] #found intexes of the most active parcels for math activity\n",
        "#thresh = min(group_contrast_math[max_ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayc8nd2XvmFk",
        "outputId": "b012c940-608d-41a2-b310-0fbd85e281cb"
      },
      "source": [
        "print(max_ind_story)\n",
        "print(max_ind_math)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 87 267 355 164 344 307  64 255 127 244 245 254 122 310 302 311 130 175\n",
            "  65 340]\n",
            "[259 229 225 208  49  83  45 143 274  28 323 325  79 324  30  95  94 296\n",
            " 262 116]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHMCaoQBgmHj"
      },
      "source": [
        "Creating an input Matrix:\n",
        "- does it work for both training and test data? \n",
        "    - Yes, I guess just when we will call function, we will send different args\n",
        "    - Don't forget to divide dataset!!! (60/40) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIDpW0LGglnY"
      },
      "source": [
        "def create_matrix(n_subjects, parcels_list, ): \n",
        "#filling matrix with values of\n",
        "\n",
        "#filling matrix for test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9vmEsTl-dT0"
      },
      "source": [
        "#test function on different subsets"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}